The rapid growth of social media has brought significant benefits to communication and information sharing, but it has also led to the proliferation of harmful online behavior, such as cyberbullying. This research focuses on developing an intelligent system to detect cyberbullying in social media posts using deep learning techniques, specifically Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) models. A dataset comprising labeled social media comments from platforms such as Facebook and Twitter was collected and preprocessed, including tokenization, padding, and encoding. Both RNN and LSTM models were trained and evaluated using this dataset. The systemâ€™s performance was measured using accuracy, precision, recall, and F1-score. Experimental results showed that the LSTM model outperformed the basic RNN model in detecting harmful textual content, owing to its ability to retain long-term dependencies. Visualizations of training progress and comparative analysis of performance metrics were used to further highlight the strengths of each model. The final system includes a simple graphical user interface (GUI) built using Tkinter, allowing users to input text and receive real-time predictions. This project demonstrates the potential of deep learning models in enhancing online safety by providing a tool for early detection of cyberbullying.
